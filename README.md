# MarkovLib
A library that helps with creation of Markov chains, of any type.
More info on Markov Chains can be found on their [wiki page](https://en.wikipedia.org/wiki/Markov_chain)

## Usage
Give me a second, I'm working on it.
